Because users don't trust FB due to past incidents, they don't believe we have good intentions
or motivations when it comes to integrity efforts. Many users don't think we are actually
trying to remove bad content and accounts because we care more about increasing
engagement and growth than protecting people and society. This belief harms the
legitimacy of our integrity efforts immensely.
Recommendations:
• Continue to invest in restoring trust in the FB brand. Efforts to increase legitimacy of
content regulation may need to include efforts to also increase trust in FB as a whole.
• Build trust by ensuring what we ship shows care and is defensible to regulators,
auditors, and our users
• Put greater prioritization on reducing harm and bad experiences
• Invest in ways to actively demonstrate to users and stakeholders that we are committed
to reducing harm both in-product (e.g., make it easier for users to report) and externally
(e.g., highlight the good work we do to prevent CEI across tech)
2 | Users believe we are biased toward and silencing minority voices due to our
moderation practices
REDACTED FOR CONGRESS
BADASS WOMEN
NO
“Between your clearly racist
and misogynistic
‘moderation' to your
laughable appeals
o
Chats
عن مصمط+
ܝܩܚܘ
10
In
